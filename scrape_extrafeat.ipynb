{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9a5de3b-c407-4de5-bce7-13b660712458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Headline  \\\n",
      "0  Lowe's beats its quarterly estimates, but nega...   \n",
      "1  Hilton plans to expand footprint in India amid...   \n",
      "2  Starting a small business is hard. Exiting can...   \n",
      "3  Factbox-What new taxes could help raise money ...   \n",
      "4  Googleâ€™s Chrome to Fetch Up to $20 Billion If ...   \n",
      "\n",
      "                                                Link        Date  \\\n",
      "0  https://finance.yahoo.com/news/lowes-beats-its...  2024-11-19   \n",
      "1  https://finance.yahoo.com/news/hilton-plans-ex...  2024-11-19   \n",
      "2  https://finance.yahoo.com/news/starting-small-...  2024-11-19   \n",
      "3  https://finance.yahoo.com/news/factbox-taxes-c...  2024-11-19   \n",
      "4  https://finance.yahoo.com/news/doj-push-google...  2024-11-19   \n",
      "\n",
      "          Source Category  \n",
      "0  Yahoo Finance  General  \n",
      "1  Yahoo Finance  General  \n",
      "2  Yahoo Finance  General  \n",
      "3  Yahoo Finance  General  \n",
      "4  Yahoo Finance  General  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "# Define the URL for Yahoo Finance news\n",
    "url = \"https://finance.yahoo.com/news\"\n",
    "\n",
    "# Make an HTTP request to the website\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Find all the <div> containers that hold the article headlines and links\n",
    "    articles = soup.find_all('div', class_='content yf-1qcp8cc')\n",
    "    \n",
    "    # Extract headlines, links, publication dates, source, and sentiment\n",
    "    news_data = []\n",
    "    for article in articles:\n",
    "        # Try to extract the headline using the h3 tag\n",
    "        headline_tag = article.find('h3', class_='clamp tw-line-clamp-3 sm:tw-line-clamp-2 yf-1qcp8cc')\n",
    "        \n",
    "        if headline_tag:\n",
    "            # Extract headline text\n",
    "            headline = headline_tag.text.strip()\n",
    "        else:\n",
    "            continue  # Skip if no headline is found\n",
    "        \n",
    "        # Extract link from the <a> tag (if exists)\n",
    "        link_tag = article.find('a', class_='subtle-link fin-size-small titles noUnderline yf-1e4diqp')\n",
    "        \n",
    "        if link_tag and 'href' in link_tag.attrs:\n",
    "            link = link_tag['href']\n",
    "            if not link.startswith('http'):\n",
    "                link = \"https://finance.yahoo.com\" + link\n",
    "        else:\n",
    "            continue  # Skip if no link is found\n",
    "\n",
    "        # Extract publication date from article metadata (if available)\n",
    "        date_tag = article.find('span', class_='Fw(b)')\n",
    "        if date_tag:\n",
    "            date = date_tag.text.strip()\n",
    "        else:\n",
    "            date = datetime.datetime.now().strftime('%Y-%m-%d')  # Default to current date if not found\n",
    "\n",
    "        # Extract source (if available)\n",
    "        source_tag = article.find('span', class_='C($tertiaryColor)')\n",
    "        source = source_tag.text.strip() if source_tag else 'Yahoo Finance'  # Default to Yahoo Finance\n",
    "\n",
    "        # Extract category (if available)\n",
    "        category_tag = article.find('div', class_='C(#fff)')\n",
    "        category = category_tag.text.strip() if category_tag else 'General'  # Default to 'General' if no category is found\n",
    "        \n",
    "        # Append the data for each article\n",
    "        news_data.append({\n",
    "            \"Headline\": headline,\n",
    "            \"Link\": link,\n",
    "            \"Date\": date,\n",
    "            \"Source\": source,\n",
    "            \"Category\": category\n",
    "        })\n",
    "\n",
    "    # Convert to a Pandas DataFrame\n",
    "    news_df = pd.DataFrame(news_data)\n",
    "\n",
    "    # Display the first few rows\n",
    "    print(news_df.head())\n",
    "\n",
    "    # Save to a CSV file for later use\n",
    "    news_df.to_csv('news_data.csv', index=False)\n",
    "\n",
    "else:\n",
    "    print(f\"Failed to retrieve the page. Status code: {response.status_code}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
